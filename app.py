import streamlit as st
from streamlit_gsheets import GSheetsConnection
import pandas as pd
import sys

# 1. ì‹œìŠ¤í…œ ì„¤ì •
if sys.stdout.encoding != 'utf-8':
    sys.stdout.reconfigure(encoding='utf-8')
st.set_page_config(page_title="ê±°ë˜ì²˜ ê´€ë¦¬", page_icon="ğŸ¢", layout="wide")

# ìŠ¤íƒ€ì¼ ì„¤ì •: ë¦¬ìŠ¤íŠ¸ ê°€ë…ì„± í–¥ìƒ
st.markdown("""
    <style>
    .small-title { font-size: 1.4rem !important; font-weight: bold; margin-bottom: 10px; }
    .contact-item { 
        background-color: #ffffff; 
        padding: 10px; 
        border: 1px solid #eee; 
        border-radius: 5px; 
        margin-bottom: 8px; 
        box-shadow: 2px 2px 5px rgba(0,0,0,0.05);
    }
    .stAppHeader {display:none;}
    </style>
    """, unsafe_allow_html=True)

# 2. êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°
url = "https://docs.google.com/spreadsheets/d/1mo031g1DVN-pcJIXk3it6eLbJrSlezH0gIUnKHaQ698/edit?usp=sharing"
st.markdown('<p class="small-title">ğŸ¢ ê±°ë˜ì²˜ í†µí•© ê´€ë¦¬</p>', unsafe_allow_html=True)

try:
    conn = st.connection("gsheets", type=GSheetsConnection)
    df = conn.read(spreadsheet=url, ttl=0)
    df = df.sort_values(by='ê±°ë˜ì²˜ëª…').reset_index(drop=True)

    # ê²€ìƒ‰ì°½ ìƒë‹¨ ë°°ì¹˜
    search_query = st.text_input("ğŸ” ê²€ìƒ‰ì°½", placeholder="ê±°ë˜ì²˜ëª… ë˜ëŠ” ì£¼ì†Œ ì…ë ¥...")

    if search_query:
        df = df[df['ê±°ë˜ì²˜ëª…'].str.contains(search_query, case=False, na=False) | 
                df['ì£¼ì†Œ'].str.contains(search_query, case=False, na=False)]

    # 4. ë¦¬ìŠ¤íŠ¸ ì¶œë ¥
    if len(df) == 0:
        st.warning("ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for i in range(0, len(df), 3):
            cols = st.columns(3)
            for j in range(3):
                if i + j < len(df):
                    row = df.iloc[i + j]
                    with cols[j]:
                        with st.container(border=True):
                            st.markdown(f"### {row['ê±°ë˜ì²˜ëª…']}")
                            
                            # ì£¼ì†Œ ë° ì§€ë„ ë§í¬
                            addr = row['ì£¼ì†Œ']
                            naver_url = f"https://map.naver.com/v5/search/{addr}"
                            st.markdown(f"ğŸ“ <a href='{naver_url}' style='text-decoration:none; color:#4A90E2; font-weight:bold;'>{addr}</a>", unsafe_allow_html=True)
                            
                            with st.expander("ğŸ‘¤ ë‹´ë‹¹ì ì—°ë½ì²˜ ë³´ê¸°"):
                                # B, C, Dì—´ ë°ì´í„° ë¶„ë¦¬
                                depts = str(row['ë¶€ì„œ']).split('\n') if pd.notna(row['ë¶€ì„œ']) else []
                                names = str(row['ë‹´ë‹¹ì']).split('\n') if pd.notna(row['ë‹´ë‹¹ì']) else []
                                phones = str(row['ì—°ë½ì²˜']).split('\n') if pd.notna(row['ì—°ë½ì²˜']) else []
                                
                                max_count = max(len(depts), len(names), len(phones))
                                
                                copy_list = [] # ë³µì‚¬ìš© í…ìŠ¤íŠ¸ ì €ì¥
                                
                                for idx in range(max_count):
                                    d = depts[idx].strip() if idx < len(depts) else "-"
                                    n = names[idx].strip() if idx < len(names) else "-"
                                    p = phones[idx].strip() if idx < len(phones) else "-"
                                    
                                    # í™”ë©´ ì¶œë ¥ìš©
                                    st.markdown(f"""
                                    <div class="contact-item">
                                        <strong>{idx+1}. {d}</strong><br>
                                        ğŸ‘¤ {n} | ğŸ“ {p}
                                    </div>
                                    """, unsafe_allow_html=True)
                                    
                                    copy_list.append(f"{idx+1}. {d} / {n} / {p}")

                                st.divider()
                                
                                # ë³µì‚¬ ê¸°ëŠ¥ (ê±°ë˜ì²˜ëª…/ì£¼ì†Œ ì œì™¸í•˜ê³  ì—°ë½ì²˜ë§Œ)
                                if copy_list:
                                    st.caption("ğŸ“‹ ì—°ë½ì²˜ ì •ë³´ ë³µì‚¬")
                                    st.code("\n".join(copy_list), language=None)

                                # ì´ë¯¸ì§€ í•˜ë‹¨ ë°°ì¹˜
                                img_url = row['ì´ë¯¸ì§€']
                                if pd.notna(img_url) and str(img_url).startswith('http'):
                                    st.markdown(f'<br><a href="{img_url}" target="_blank"><img src="{img_url}" style="width:100px; border-radius:5px;"></a>', unsafe_allow_html=True)
                                    st.caption("ì‚¬ì§„ í´ë¦­ ì‹œ í™•ëŒ€")

except Exception as e:
    st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

st.caption("Â© 2026 ê±°ë˜ì²˜ ê´€ë¦¬ ì‹œìŠ¤í…œ | ìŠ¤ë…¸ìš°ë‹˜ ì „ìš©")
